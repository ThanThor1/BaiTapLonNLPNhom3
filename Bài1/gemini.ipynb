{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaH100","dataSources":[{"sourceType":"competition","sourceId":118448,"databundleVersionId":14559231},{"sourceType":"datasetVersion","sourceId":14266495,"datasetId":9103891,"databundleVersionId":15067026},{"sourceType":"datasetVersion","sourceId":14265113,"datasetId":9102883,"databundleVersionId":15065519,"isSourceIdPinned":false}],"dockerImageVersionId":31236,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import google.generativeai as genai\nimport time\nimport re\nimport os\nfrom google.api_core import exceptions\n\n# 1. CẤU HÌNH\nAPI_KEY = \"AIzaSyCrk5HNqKq_VTFGb_KbFhYv0OpwhAR_MxQ\"  \ngenai.configure(api_key=API_KEY)\n\nmodel = genai.GenerativeModel('gemini-2.5-flash')\n\ninput_dir = \"/kaggle/input/src-data\" \noutput_dir = \"/kaggle/working\"      \noutput_file = os.path.join(output_dir, \"summary_evaluation_results.txt\")\n\n# 2. HÀM ĐỌC & XỬ LÝ\ndef read_file(path):\n    if not os.path.exists(path): return []\n    with open(path, 'r', encoding='utf-8') as f:\n        return [l.strip() for l in f.readlines() if l.strip()]\n\nen_lines = read_file(os.path.join(input_dir, \"english_original.txt\"))\nref_lines = read_file(os.path.join(input_dir, \"vietnamese_reference.txt\"))\ntrans_lines = read_file(os.path.join(input_dir, \"vietnamese_translated.txt\"))\n\nmin_len = min(len(en_lines), len(ref_lines), len(trans_lines))\nen_lines, ref_lines, trans_lines = en_lines[:min_len], ref_lines[:min_len], trans_lines[:min_len]\n\nBATCH_SIZE = 128\nall_scores = []\n\ndef get_scores_with_retry(batch_data, retries=5):\n    prompt = (\n        \"Role: Translation QA. Task: Score Target vs Reference based on Source.\\n\"\n        \"Scale: 0-10.\\n\"\n        \"Format per line: ID: [id] | Score: [number] | Reason: [short text]\\n\\n\"\n        \"Data:\\n\"\n    )\n    for item in batch_data:\n        prompt += f\"ID: {item['id']} | Src: {item['en']} | Ref: {item['ref']} | Tgt: {item['target']}\\n\"\n\n    wait_time = 20\n    \n    for attempt in range(retries):\n        try:\n            response = model.generate_content(prompt)\n            return response.text.strip()\n        except exceptions.ResourceExhausted:\n            print(f\"   [!] Quá hạn mức (429). Đang nghỉ {wait_time}s...\")\n            time.sleep(wait_time)\n            wait_time += 10\n        except Exception as e:\n            print(f\"   [!] Lỗi khác: {e}\")\n            time.sleep(5)\n    return None\n\n# 3. CHẠY CHÍNH\nprint(f\"Bắt đầu chấm câu với Gemini 2.5 Flash...\")\n\nif os.path.exists(output_file):\n    os.remove(output_file)\n\nfor i in range(0, min_len, BATCH_SIZE):\n    batch = []\n    for j in range(i, min(i + BATCH_SIZE, min_len)):\n        batch.append({\"id\": j + 1, \"en\": en_lines[j], \"ref\": ref_lines[j], \"target\": trans_lines[j]})\n    \n    print(f\"-> Batch {i//BATCH_SIZE + 1}: Dòng {i+1} - {i+len(batch)}\")\n    raw_result = get_scores_with_retry(batch)\n    \n    if raw_result:\n        with open(output_file, 'a', encoding='utf-8') as f_out:\n            f_out.write(raw_result + \"\\n\")\n            found_scores = re.findall(r\"Score.*?(\\d+(?:\\.\\d+)?)\", raw_result, re.IGNORECASE)\n            \n            valid_batch_scores = []\n            for s in found_scores:\n                try:\n                    val = float(s)\n                    if 0 <= val <= 10:\n                        all_scores.append(val)\n                        valid_batch_scores.append(val)\n                except: pass\n            \n            if valid_batch_scores:\n                avg_now = sum(valid_batch_scores)/len(valid_batch_scores)\n                print(f\"   [OK] Batch Avg: {avg_now:.2f}\")\n            else:\n                print(f\"   [Warning] Không thấy điểm. Raw: {raw_result[:50]}...\")\n                \n    time.sleep(5)\n\nprint(f\"\\n--- HOÀN THÀNH. Tổng số điểm thu được: {len(all_scores)}/{min_len} ---\")\nif all_scores:\n    print(f\"Điểm trung bình toàn bộ: {sum(all_scores)/len(all_scores):.2f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-23T09:54:27.467161Z","iopub.execute_input":"2025-12-23T09:54:27.467788Z","iopub.status.idle":"2025-12-23T10:17:49.762496Z","shell.execute_reply.started":"2025-12-23T09:54:27.467772Z","shell.execute_reply":"2025-12-23T10:17:49.762039Z"}},"outputs":[{"name":"stdout","text":"Bắt đầu chấm câu với Gemini 2.5 Flash...\n-> Batch 1: Dòng 1 - 128\n   [OK] Batch Avg: 7.07\n-> Batch 2: Dòng 129 - 256\n   [OK] Batch Avg: 5.78\n-> Batch 3: Dòng 257 - 384\n   [OK] Batch Avg: 6.04\n-> Batch 4: Dòng 385 - 512\n   [OK] Batch Avg: 6.73\n-> Batch 5: Dòng 513 - 640\n   [OK] Batch Avg: 5.26\n-> Batch 6: Dòng 641 - 768\n   [OK] Batch Avg: 6.59\n-> Batch 7: Dòng 769 - 896\n   [OK] Batch Avg: 6.12\n-> Batch 8: Dòng 897 - 1024\n   [OK] Batch Avg: 5.86\n-> Batch 9: Dòng 1025 - 1152\n   [OK] Batch Avg: 6.02\n-> Batch 10: Dòng 1153 - 1268\n   [OK] Batch Avg: 4.42\n\n--- HOÀN THÀNH. Tổng số điểm thu được: 1268/1268 ---\nĐiểm trung bình toàn bộ: 6.00\n","output_type":"stream"}],"execution_count":4}]}